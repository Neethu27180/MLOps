
name: MLOps Pipeline

on:
  push:
    branches:
      - main

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        pip install -r tourism_project/model_deployment/requirements.txt
        pip install mlflow huggingface_hub joblib pandas scikit-learn

    - name: Log in to Hugging Face Hub
      run: |
        echo "${{ secrets.HF_TOKEN }}" | huggingface-cli login --token-value-stdin

    - name: Run Data Preparation
      run: |
        python tourism_project/data_registration/data_preparation.py
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}


    - name: Run Model Building and Evaluation
      run: |
        python tourism_project/model_building/model_build_eval.py
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
        MLFLOW_TRACKING_URI: file:///tmp/mlruns # Log MLflow artifacts locally in the runner


    - name: Upload MLflow artifacts
      uses: actions/upload-artifact@v4
      with:
        name: mlflow-artifacts
        path: /tmp/mlruns

    - name: Deploy Model to Hugging Face Space
      run: |
        # This step assumes the Dockerfile, requirements.txt, and app.py are in
        # tourism_project/model_deployment and the model and X_train.csv
        # are in the expected locations relative to the Dockerfile's WORKDIR (/app).
        # The Dockerfile copies these files.
        # The Hugging Face Space will build the Docker image and run the app.py.
        # No specific action needed here other than ensuring the files are in the repo
        # and will be picked up by the Hugging Face Space build process.
        echo "Deployment files are ready in the repository. Hugging Face Space will handle the build and deployment on push."

